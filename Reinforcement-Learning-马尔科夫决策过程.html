<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">

<meta name="baidu-site-verification" content="pzKra37kyC">
<meta name="google-site-verification" content="Tpp8m_k5m4Tzi6cI_Yzh5M10Yb0Vh4iUa8WMJqGE3kg">
<meta name="msvalidate.01" content="6848BAEF6B569BCE80C501D1FA6868F6">

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Monte Yang">


    <meta name="subtitle" content="朝着咸鱼的反方向努力">


    <meta name="description" content="❤MY">


    <meta name="keywords" content="3D Deep learning, Monte Yang, 深度学习, 算法">


<title>Reinforcement Learning-马尔可夫决策过程 | MonteYang&#39;s Blog</title>



    <link rel="icon" href="/image/logo32x32.jpg">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="MonteYang's Blog" type="application/atom+xml">
</head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">MonteYang&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">MonteYang&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>

        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>

    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Reinforcement Learning-马尔可夫决策过程</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Monte Yang</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">2020-2-9&nbsp;&nbsp;23:15:16</a>
                        </span>
                    
                    
                        <span class="post-category">
                            Category:
                            
                                <a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <blockquote>
<p>马尔科夫性 - 马尔可夫过程 - 马尔可夫奖励过程 - 马尔可夫决策过程</p>
</blockquote>
<a id="more"></a>

<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>马尔可夫决策过程（Markov Decision Processes, MDPs）是对强化学习问题的数学描述。</p>
<ul>
<li>要求环境是<strong>全观测</strong>的。</li>
</ul>
<hr>
<h1 id="马尔可夫性"><a href="#马尔可夫性" class="headerlink" title="马尔可夫性"></a>马尔可夫性</h1><blockquote>
<p>“只要知道现在，将来和过去是条件独立的，可以抛去过去所有的信息。”</p>
</blockquote>
<p>定义：如果在t时刻的状态$S_t$满足下式，则这个状态被称为<strong>马尔科夫状态</strong>，即该状态满足马尔科夫性</p>
<p>$$ P[S_{t+1}|S_{t}] = P[S_{t+1}|S_1, …, S_t] $$</p>
<p>注：</p>
<ul>
<li>状态$S_t$包含了所有历史相关信息，即之前的信息都可以在该状态上体现出来</li>
<li>所以要求环境是全观测的，(如果是部分观测的话，状态信息有缺失)。</li>
<li><strong>是否满足马尔可夫性与状态的定义息息相关</strong></li>
</ul>
<p>例子：</p>
<ul>
<li>下棋</li>
<li>俄罗斯方块</li>
</ul>
<p>有了马尔可夫状态之后：</p>
<ul>
<li>定义状态转移矩阵</li>
<li>忽略时间的影响</li>
</ul>
<hr>
<h1 id="状态转移矩阵"><a href="#状态转移矩阵" class="headerlink" title="状态转移矩阵"></a>状态转移矩阵</h1><p>状态转移概率指从一个马尔可夫状态 s 跳转到后继状态 (successor<br>state) s′ 的概率。</p>
<p>$$ \mathcal{P} _ {ss^{‘}} = \mathbb{P} [S_{t+1} = s^{‘} | S_t = s] $$</p>
<p>若状态是<strong>离散</strong>的（有限个）：<br>所有的状态组成行，所有后继状态组成列，得到状态转移矩阵</p>
<p>$$ \mathcal{P} =<br>\begin{bmatrix}<br>\mathcal{P} _ {11} &amp; … &amp; \mathcal{P} _ {1n} \<br>… &amp; … &amp; … \<br>\mathcal{P} _ {n1} &amp; … &amp; \mathcal{P} _ {nn}  \<br>\end{bmatrix}$$</p>
<ul>
<li>$n$为状态个数</li>
<li>每行元素相加为1</li>
</ul>
<p>若状态是<strong>连续</strong>的，即无限个状态，适合用本节最上式的函数形式表示。</p>
<ul>
<li>此时，$\int_{s’}\mathcal{P}(s’|s)=1$</li>
</ul>
<hr>
<h1 id="马尔可夫过程"><a href="#马尔可夫过程" class="headerlink" title="马尔可夫过程"></a>马尔可夫过程</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>一个马尔可夫过程 (Markov process, MP) 是一个无记忆的随机过程，即一些马尔可夫状态的序列。</p>
<p>马尔可夫过程可由一个二元组来定义 $&lt;S,\mathcal{P}&gt;$</p>
<ul>
<li>$S$：代表状态集合</li>
<li>$\mathcal{P}$：代表状态转移矩阵</li>
</ul>
<blockquote>
<p>通常假设$\mathcal{P}$是存在且稳定的<br>当$\mathcal{P}$不稳定时，采用在线学习、快速学习等方法</p>
</blockquote>
<h2 id="马尔可夫过程的例子"><a href="#马尔可夫过程的例子" class="headerlink" title="马尔可夫过程的例子"></a>马尔可夫过程的例子</h2><p><img src="/images/RL-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%BE%8B%E5%AD%90.png" alt="马尔可夫链"></p>
<ul>
<li>马尔可夫过程中的终止状态有2种：<ul>
<li>时间终止</li>
<li>状态终止</li>
</ul>
</li>
</ul>
<h2 id="片段（Episode）"><a href="#片段（Episode）" class="headerlink" title="片段（Episode）"></a>片段（Episode）</h2><p>定义： 强化学习中，从初始状态 $S_1$ 到终止状态 $S_T$ 的序列过程。</p>
<p>$$S_1, S_2, …, S_T$$</p>
<hr>
<h1 id="马尔可夫奖励过程"><a href="#马尔可夫奖励过程" class="headerlink" title="马尔可夫奖励过程"></a>马尔可夫奖励过程</h1><h2 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h2><p>在马尔可夫过程的基础上，<strong>在转移关系中赋予不同的奖励值</strong>，即得到马尔可夫奖励过程。</p>
<p>马尔可夫奖励 (Markov Reward Process, MRP) 过程由一个四元组组成 $⟨S, \mathcal{P}, \mathcal{R}, γ⟩$</p>
<ul>
<li>S：状态集合</li>
<li>$\mathcal{P}$：状态转移矩阵</li>
<li>$\mathcal{R}$：奖励函数， $\mathcal{R}(s)$ 描述了在状态 s 的奖励，$\mathcal{R}(s) = E [\mathcal{R}_{t+1}|S_t = s]$</li>
<li>$γ$：衰减因子</li>
</ul>
<h2 id="回报值"><a href="#回报值" class="headerlink" title="回报值"></a>回报值</h2><ul>
<li>奖励值：对一个<strong>状态</strong>的评价</li>
<li>回报值：对一个<strong>片段</strong>的评价</li>
</ul>
<p>回报值（return $G_t$）是从时间t处开始的累积衰减奖励</p>
<p>$$G_t = R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + …$$</p>
<h2 id="MRPs中的值函数"><a href="#MRPs中的值函数" class="headerlink" title="MRPs中的值函数"></a>MRPs中的值函数</h2><blockquote>
<p>为什么要值函数？<br>回报值是一个片段的结果，存在很大的样本偏差<br>回报值的角标是 t，值函数关注的是状态 s</p>
</blockquote>
<p>一个 MRP 的值函数如下定义<br>$$v(s) = \mathbb{E}[G_t|S_t = s]$$</p>
<p>这里的值函数针对的是状态 s，所以称为<strong>状态值函数</strong>，又称 V 函数</p>
<h2 id="MRPs中的贝尔曼方程（重点）"><a href="#MRPs中的贝尔曼方程（重点）" class="headerlink" title="MRPs中的贝尔曼方程（重点）"></a>MRPs中的贝尔曼方程（重点）</h2><p>$$\begin{aligned}v(s)&amp;=\mathbb{E}[G_t|S_t=s] \ &amp;=\mathbb{E}[ R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + .. S_t=s] \ &amp;=\mathbb{E}[ R_{t+1} + \gamma G_{t+1} | S_t=s ] \ &amp;=\mathbb{E}[ R_{t+1} + \gamma v(S_{t+1}) | S_t=s ]\end{aligned}$$</p>
<p>当前状态的值函数包括两部分：</p>
<ul>
<li>第一项：瞬时奖励 $R_{t+1}$</li>
<li>第二项：后继状态 $S_{t+1}$ 的值函数乘衰减系数</li>
</ul>
<p>如果已知转移矩阵 $P$，那么<br>$$\begin{aligned} v(s) &amp;= \mathbb{E} [R_{t+1} + γv(S_{t+1}) | S_t = s] \    &amp;= \mathbb{E} [Rt+1jSt = s] + γ \mathbb{E}[v(S_{t+1})|S_t = s] \&amp;= \mathcal{R}(s) + γ ∑\mathcal{P}_{ss^′}v(s^′)\end{aligned}$$</p>
<p>矩阵-向量形式为：</p>
<p>$$v = \mathcal{R} + \gamma \mathcal{P} v$$</p>
<p><img src="/images/RL-MRPs%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B.png" alt></p>
<p>本质上是一个线性方程，可以直接解：</p>
<p><img src="/images/RL-MRP%E8%A7%A3%E8%B4%9D%E5%B0%94%E6%9B%BC.png" alt></p>
<p>直接求解只适用于小型MRPs：</p>
<ul>
<li>计算复杂度$O(n^3)$</li>
<li>要求已知 $\mathcal{P}$</li>
</ul>
<hr>
<h1 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h1><p>在 MRP 中引入决策即得到了马尔可夫决策过程（Markov Decision Processes, MDPs）</p>
<h2 id="定义-2"><a href="#定义-2" class="headerlink" title="定义"></a>定义</h2><p>一个马尔可夫决策过程 (MDPs) 由一个五元组构成 $⟨S, \mathcal{A}, \mathcal{P}, \mathcal{R}, γ⟩$</p>
<ul>
<li><p>$\mathcal{A}$ ： 动作的集合</p>
</li>
<li><p>$\mathcal{P}$ ： 状态转移矩阵，<br>$$\mathcal{P}<em>{ss^{‘}}^{a} = \mathbb{P}[ S</em>{t+1}=s’ | S_t=s, A_{t}=a]$$</p>
</li>
<li><p>$\mathcal{R}(s,a)$：奖励函数， 表示在状态s做动作a的奖励。$\mathcal{R}(s) = E [\mathcal{R}_{t+1}|S_t = s]$</p>
</li>
</ul>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>在 MDPs 中，一个策略 (Policy)π 是在给定状态下的动作的概率分布</p>
<p>$$\pi(a | s) = \mathbb{P}[ A_t = a | S_t = s ]$$</p>
<p><img src="/images/RL-MDP%E7%AD%96%E7%95%A5%E5%88%86%E5%B8%83.png" alt></p>
<ul>
<li>策略是时间稳定的，只与s有关，与时间t无关</li>
<li>是RL问题的终极目标</li>
<li>如果分布是 one-hot 的，那么为确定性策略，否则为随机策略</li>
</ul>
<p><img src="/images/RL-%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%AD%96%E7%95%A5.png" alt></p>
<h2 id="MDPs与MRPs之间的关系"><a href="#MDPs与MRPs之间的关系" class="headerlink" title="MDPs与MRPs之间的关系"></a>MDPs与MRPs之间的关系</h2><p>如果MDP问题给定策略$\pi$，则会退化成MRP问题。</p>
<h2 id="MDPs中的值函数"><a href="#MDPs中的值函数" class="headerlink" title="MDPs中的值函数"></a>MDPs中的值函数</h2><ol>
<li><p>状态值函数（V函数）</p>
<ul>
<li>定义：从状态s开始，使用策略$\pi$得到的期望回报值</li>
</ul>
<p>$$v_{\pi}(s) = \mathbb{E}_\pi[G_t|S_t = s]$$</p>
</li>
</ol>
<ol start="2">
<li><p>状态动作值函数（Q函数）</p>
<ul>
<li><p>定义：MDPs 中的状态动作值函数是从状态 s 开始，执行动作 a， <strong>然后</strong>使用策略 π 得到的期望回报值</p>
<blockquote>
<p>动作a不一定来自于策略 $\pi$，实际上是做完动作 a之后，才遵循策略 $\pi$ 进行动作选择</p>
</blockquote>
<p>$$q_{\pi}(s, a) = \mathbb{E}_\pi[ G_t | S_t = s, A_t = a ]$$</p>
</li>
</ul>
</li>
</ol>
<h2 id="贝尔曼期望方程"><a href="#贝尔曼期望方程" class="headerlink" title="贝尔曼期望方程"></a>贝尔曼期望方程</h2><p>和 MRP 相似， MDPs 中的值函数也能分解成<strong>瞬时奖励</strong>和<strong>后继状态的值函数</strong>两部分</p>
<p>$$ v_ \pi(s)=\mathbb{E}_ \pi [ R_{t+1} + \gamma v_ \pi(S_{t+1}) | S_t=s ] $$</p>
<p>$$ q_ \pi(s,a)=\mathbb{E}_ \pi [ R_{t+1} + \gamma q_ \pi(S_{t+1}, A_{t+1}) | S_t=s, A_t=a] $$</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Monte Yang</span>
                    </p>
                
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="external nofollow noopener noreferrer">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Reinforcement-Learning/"># Reinforcement Learning</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">Back</a>
                <span>· </span>
                <a href="/">Home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/LeetCode-41-50%E9%A2%98.html">LeetCode-41-50题</a>
            
            
            <a class="next" rel="next" href="/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-PointNet.html">论文阅读-PointNet</a>
            
        </section>


    </article>
</div>



    <div id="gitalk-container"></div>
    <script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>

<link rel="stylesheet" href="//unpkg.com/gitalk/dist/gitalk.css">
<script src="//unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
      var gitalk = new Gitalk({
        clientID: 'c3f96e8fb86bf653ad6c',
        clientSecret: '67954d29616c8cd146127aa2147f7e637aceb151',
        repo: 'MonteYang.github.io',
        owner: 'MonteYang',
        admin: 'MonteYang',
        id: md5(location.pathname),      
        labels: 'Gitalk'.split(',').filter(l => l),
        perPage: 10,
        pagerDirection: 'last',
        createIssueManually: false,
        distractionFreeMode: false
      })
      gitalk.render('gitalk-container')
</script>



        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>2019 ~ 2020</span>
        <!-- <span>© Monte Yang | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span> -->
        <span>© Monte Yang | Powered by <a href="https://hexo.io" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a></span>
    </div>
</footer>

    </div>
</body>
</html>
